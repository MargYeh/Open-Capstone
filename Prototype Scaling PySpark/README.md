# Open Capstone - Market Research - Step 6 0 Pipeline Scaling with Pyspark

This step of the project refactored the previous Pipeline Prototype to work with Spark instead of Pandas. Spark is faster when working with large sets of data, making this a necessary step if working with big data. This part of the project was run on Databricks Community Edition, with the corresponding files located in the Databricks Working directory. Thoughts and a walkthrough of the process are shown in the Progress Slides PDF.

The notebooks in DataBricks Working will be uploaded in the future to Azure databricks. It uses Databrick's DBFS for storage instead of connecting to Azure Blob Storage. 
